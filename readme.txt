TaskA
Segmentation
--------------
The code, named MIA_SkinLesion_Segmentation, implements an image segmentation algorithm, leveraging the DeeplabV3 (https://github.com/leimao/DeepLab-V3) provided by TorchVision.
Using the ResNet50 to achieve faster training and inference speed and to reduce the risk of overfitting.
The file named model_2024-05-07 18-25-17.pth is the pre-trained model weights

The script will train the model on the lesion dataset, evaluate it, and display segmentation results for both validation and new test images.
Training and validation losses, as well as validation accuracy, are printed at the end of each epoch.
Models are saved periodically, ensuring that you can return to a specific state of training.
Final segmentations are displayed using matplotlib for visual inspection.


TaskB
Symmetry Analysis Workflow
--------------------------

This section outlines the procedure for evaluating the symmetry of images using a pre-trained model based on masks generated from TaskA.

Process Overview:
1. Model Loading:
   - Load the pre-trained model weights from the 'bestmodel' file.
   
2. Mask Analysis:
   - Utilize masks stored in a specific folder, generated by TaskA, for input into the symmetry analysis.

3. Symmetry Assessment:
   - Conduct the symmetry analysis using the 'testskin' script, which processes the masks and evaluates their symmetry.

Training Details:
- The model was trained using the 'dl_symmetry' file, which includes all necessary code and training parameters.

Usage Instructions:
- To perform the analysis, execute the following command:
  python testskin.py --model-path path/to/bestmodel --mask-dir path/to/mask-folder

Note: Replace 'path/to/bestmodel' and 'path/to/mask-folder' with the actual paths to your model file and mask directory respectively.

TaskC
Classification
In the file TaskB_CNNclassification.ipynb, I have used image from dataset to train the CNN to classify the test data. The code first load the dataset and resize them. Then I have used the data augmentation method on the data to generate more data for training. The CNN also was built to extract the feature and make prediction. To run the code, you can directly go to the def load_and_preprocess_image(image_path) part in the last cell and change the base_path to the path of your test file. Then you should also have your model by downloading it from:(https://drive.google.com/file/d/1HQsnLWj1IrrOIzpvJmTreIdQ74exto4a/view?usp=drive_link). Then you can run the code to see the predicted results.

Random Forest method
Algorithm overview:
1. Feature Extraction
The code extracts the following features from each skin lesion image:
Shape features: area and perimeter of the lesion
Edge features: number of edge pixels in the lesion
Texture features: variance of the Laplacian of the lesion
Symmetry features: encoded symmetry label (fully symmetric, symmetric in 1 axis, or fully asymmetric)
2. Classification Model
The code uses a random forest classifier for the classification task. The hyperparameters of the random forest model are tuned using grid search with cross-validation. The best model is selected based on the highest accuracy score.
3. Evaluation
The trained model is evaluated on the testing set using accuracy and confusion matrix. The accuracy represents the proportion of correctly classified samples, while the confusion matrix provides a detailed breakdown of the model's performance for each class.